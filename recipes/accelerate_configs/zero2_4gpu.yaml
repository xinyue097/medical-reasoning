compute_environment: LOCAL_MACHINE
debug: false
deepspeed_config:
  bf16:
    enabled: true
  gradient_clipping: 1.0
  # 4-GPU Batch size parameters - MUST MATCH config2.yaml
  gradient_accumulation_steps: 4        # ✅ For 4 GPUs
  train_batch_size: 128                 # ✅ 8 × 4 × 4 = 128
  train_micro_batch_size_per_gpu: 8     # ✅ Match config2.yaml per_device_train_batch_size

  offload_optimizer_device: none
  offload_param_device: none
  zero_stage: 2
  allgather_bucket_size: 200000000
  reduce_bucket_size: 200000000
  overlap_comm: true
  contiguous_gradients: true
  sub_group_size: 1000000000000
  reduce_scatter: true
  allgather_partitions: true
  use_multi_rank_bucket_allreduce: true
  zero_allow_untested_optimizer: true
distributed_type: DEEPSPEED
downcast_bf16: false
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 4                        # ✅ 4 GPUs
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
